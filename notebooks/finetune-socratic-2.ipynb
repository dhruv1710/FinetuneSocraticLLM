{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-03-03T10:36:45.891814Z","iopub.status.busy":"2025-03-03T10:36:45.891415Z","iopub.status.idle":"2025-03-03T10:36:45.905124Z","shell.execute_reply":"2025-03-03T10:36:45.902929Z","shell.execute_reply.started":"2025-03-03T10:36:45.891783Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2025-03-03T10:36:49.463653Z","iopub.status.busy":"2025-03-03T10:36:49.463198Z","iopub.status.idle":"2025-03-03T10:36:50.026694Z","shell.execute_reply":"2025-03-03T10:36:50.024722Z","shell.execute_reply.started":"2025-03-03T10:36:49.463621Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'wandb' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-d8ca7b2f1402>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mwb_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_secrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_secret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"WANDB_TOKEN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwb_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m run = wandb.init(\n\u001b[1;32m     13\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Fine-tune Llama 3 8B on Socratic Chat Dataset'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"]}],"source":["from huggingface_hub import login\n","from kaggle_secrets import UserSecretsClient\n","user_secrets = UserSecretsClient()\n","\n","hf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n","\n","login(token = hf_token)\n","\n","wb_token = user_secrets.get_secret(\"WANDB_TOKEN\")\n","\n","wandb.login(key=wb_token)\n","run = wandb.init(\n","    project='Fine-tune Llama 3 8B on Socratic Chat Dataset', \n","    job_type=\"training\", \n","    anonymous=\"allow\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"execution_failed":"2025-03-03T10:37:06.241Z","iopub.execute_input":"2025-03-03T10:37:00.659549Z","iopub.status.busy":"2025-03-03T10:37:00.659110Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37e1a2f25f324043ad5594a754e1f66d","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/255 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13fb03de5ed94f588add614bf7685e69","version_major":2,"version_minor":0},"text/plain":["SocraticChat-50728.json:   0%|          | 0.00/495M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset('FreedomIntelligence/SocraticChat',split='train[0:500]')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"execution_failed":"2025-03-03T10:37:06.242Z"},"trusted":true},"outputs":[],"source":["dataset[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"execution_failed":"2025-03-03T10:37:06.242Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","from trl import setup_chat_format\n","\n","# QLoRA config\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch_dtype,\n","    bnb_4bit_use_double_quant=True,\n",")\n","\n","# Load model\n","model = AutoModelForCausalLM.from_pretrained(\n","    'meta-llama/Meta-Llama-3-8B',\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    attn_implementation=attn_implementation\n",")\n","tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3-8B')\n","model, tokenizer = setup_chat_format(model, tokenizer)"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2025-03-03T10:37:33.761887Z","iopub.status.busy":"2025-03-03T10:37:33.761498Z","iopub.status.idle":"2025-03-03T10:37:33.838382Z","shell.execute_reply":"2025-03-03T10:37:33.837116Z","shell.execute_reply.started":"2025-03-03T10:37:33.761850Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'LoraConfig' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4d54e4b45f2d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# LoRA config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m peft_config = LoraConfig(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlora_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlora_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'LoraConfig' is not defined"]}],"source":["# LoRA config\n","peft_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",")\n","model = get_peft_model(model, peft_config)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-03-03T10:37:37.009054Z","iopub.status.busy":"2025-03-03T10:37:37.008630Z","iopub.status.idle":"2025-03-03T10:37:37.013819Z","shell.execute_reply":"2025-03-03T10:37:37.012880Z","shell.execute_reply.started":"2025-03-03T10:37:37.009008Z"},"trusted":true},"outputs":[],"source":["def formatting_prompts_func(example):\n","    k=[]\n","    for converse in example['converstations']:\n","        k.append({'role':converse['from'], 'content':'assistant' if converse['value'] == 'gpt' else 'user'})\n","    example['text'] = tokenizer.apply_chat_template(k, tokenize=False)\n","    return example"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-03-03T10:37:47.516286Z","iopub.status.busy":"2025-03-03T10:37:47.515951Z","iopub.status.idle":"2025-03-03T10:37:47.527287Z","shell.execute_reply":"2025-03-03T10:37:47.525998Z","shell.execute_reply.started":"2025-03-03T10:37:47.516259Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'dataset' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-608f0c910bf3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatting_prompts_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"]}],"source":["dataset = dataset.map(formatting_prompts_func, num_proc=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_arguments = TrainingArguments(\n","    output_dir=new_model,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    gradient_accumulation_steps=2,\n","    optim=\"paged_adamw_32bit\",\n","    num_train_epochs=1,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=0.2,\n","    logging_steps=1,\n","    warmup_steps=10,\n","    logging_strategy=\"steps\",\n","    learning_rate=2e-4,\n","    fp16=False,\n","    bf16=False,\n","    group_by_length=True,\n","    report_to=\"wandb\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset,\n","    peft_config=peft_config,\n","    max_seq_length=512,\n","    dataset_text_field=\"text\",\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n","    packing= False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.train()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
